{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_thread_timings(\n",
    "    run_output_file_path,\n",
    "    statistics=(\"mean\", \"std\", \"min\", \"max\"),\n",
    "    operations=(\"Up. determin.\", \"Up. stochastic\", \"Weight\")\n",
    "):\n",
    "    table_rule_line_numbers = []\n",
    "    with open(run_output_file_path, \"r\") as output_file:\n",
    "        for line_number, line in enumerate(output_file):\n",
    "            if line.strip(\" \").startswith(\"â”€\" * 50):\n",
    "                table_rule_line_numbers.append(line_number)\n",
    "    number_of_ranks = len(table_rule_line_numbers) // 3\n",
    "    timing_dataframes = {}\n",
    "    for rank in range(number_of_ranks):\n",
    "        _, header_rule_line, end_rule_line = table_rule_line_numbers[rank * 3:(rank + 1) * 3]\n",
    "        timing_dataframes[f\"Rank {rank}\"] = pd.read_fwf(\n",
    "            run_output_file_path,\n",
    "            skiprows=(\n",
    "                list(range(0, header_rule_line - 1)) \n",
    "                + [header_rule_line] \n",
    "                + list(range(end_rule_line , line_number + 1))\n",
    "            ),\n",
    "            header=0\n",
    "        )\n",
    "    summary_stats = {key: [] for key in [\"rank\", \"operation\"] + list(statistics)}\n",
    "    for rank in range(number_of_ranks):\n",
    "        dataframe = timing_dataframes[f\"Rank {rank}\"]\n",
    "        for operation in operations:\n",
    "            timings = pd.to_timedelta(\n",
    "                dataframe[dataframe.Section.str.strip().str.startswith(operation)].time\n",
    "            )\n",
    "            summary_stats[\"rank\"].append(rank)\n",
    "            summary_stats[\"operation\"].append(operation)\n",
    "            for stat in statistics:\n",
    "                summary_stats[stat].append(getattr(timings, stat)().total_seconds())\n",
    "    summary_stats = pd.DataFrame(summary_stats)\n",
    "    return timing_dataframes, summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank       operation      mean       std      min     max\n",
      "0      0   Up. determin.  1.202200  0.213851  0.93000  2.0200\n",
      "1      0  Up. stochastic  1.046350  0.144915  0.84700  1.4900\n",
      "2      0          Weight  0.006631  0.008476  0.00203  0.0416\n",
      "3      1   Up. determin.  1.318625  0.776672  0.90900  4.0500\n",
      "4      1  Up. stochastic  1.044950  0.181585  0.75400  1.7900\n",
      "5      1          Weight  0.004057  0.005337  0.00203  0.0289\n",
      "6      2   Up. determin.  1.320475  0.276602  0.92600  1.7900\n",
      "7      2  Up. stochastic  1.160150  0.339650  0.74000  2.4000\n",
      "8      2          Weight  0.005271  0.012202  0.00203  0.0751\n",
      "9      3   Up. determin.  1.562925  0.787751  0.97700  3.8300\n",
      "10     3  Up. stochastic  1.090925  0.319656  0.72500  2.8200\n",
      "11     3          Weight  0.007265  0.008803  0.00211  0.0425\n"
     ]
    }
   ],
   "source": [
    "run_output_file_path = \"ParticleDAScaling160Longer1BLASThread.o395270\"\n",
    "timing_dataframes, summary_stats = get_per_thread_timings(run_output_file_path)\n",
    "print(summary_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlo-py311-pandas2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
